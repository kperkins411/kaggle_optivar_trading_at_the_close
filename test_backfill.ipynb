{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc  \n",
    "import os  \n",
    "import time  \n",
    "import warnings \n",
    "from itertools import combinations  \n",
    "from warnings import simplefilter \n",
    "import joblib  \n",
    "import playground.optivarfuncs as of\n",
    "import lightgbm as lgb  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "is_offline = False \n",
    "is_train = True  \n",
    "is_infer = True \n",
    "max_lookback = np.nan \n",
    "split_day = 435  \n",
    "import polars as pl\n",
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "def getdfstats(numb_days= 1, stocks=list(range(200)), numb_secs_day= 55):\n",
    "    '''\n",
    "    generate a dataframe to hold latest stock near and far prices\n",
    "    num_days: how many days in dataframe\n",
    "    stocks: stock ids\n",
    "    n_nulls: first n rows per day have near and far price = NaN\n",
    "    drop_days: remove these days from dataframe\n",
    "    '''\n",
    "    stockl = np.concatenate(numb_days*[list(itertools.repeat(n, numb_secs_day)) for n in stocks], axis=0).tolist()\n",
    "    dayl = [np.trunc(d/(numb_secs_day*len(stocks))) for d in list(range(numb_days*numb_secs_day*len(stocks)))]\n",
    "    vall = [0 for i in list(range(len(stocks)*numb_days*numb_secs_day))]\n",
    "    secl = [(d % numb_secs_day)*10 for d in list(range(numb_days*numb_secs_day*len(stocks)))]\n",
    "\n",
    "    df = pd.DataFrame(data={'stock_id': stockl, 'date_id': dayl, 'far_price': vall, 'near_price': vall, 'seconds_in_bucket': secl,'dummynp': vall,'dummyfp': vall})\n",
    "    return df\n",
    "\n",
    "# getdfstats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata=pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import playground.optivarfuncs as of\n",
    "\n",
    "def fillrow(row,dfstats):\n",
    "    #if NaN in row.near_price or row.far_price then replace it with \n",
    "    #value in dfstats for the corresponding stock_id and seconds in bucket slot\n",
    "    #if not NaN then save otherwise save row.near_price and row.far_price in dfstats\n",
    "    # ex. df.apply(fillrow, axis=1, args=(dfstats,))\n",
    "\n",
    "    rowstats=(dfstats.stock_id==row.stock_id) &(dfstats.seconds_in_bucket==row.seconds_in_bucket)\n",
    "    \n",
    "    if row.near_price==np.NaN:\n",
    "        row.near_price=dfstats.loc[rowstats,'near_price']\n",
    "        dfstats.loc[rowstats,'dummynp']=0\n",
    "    else:\n",
    "        dfstats.loc[rowstats,'near_price']=row.near_price\n",
    "        dfstats.loc[rowstats,'dummynp']=1\n",
    "    \n",
    "    if row.far_price==np.NaN:\n",
    "        row.far_price=dfstats.loc[rowstats,'far_price']\n",
    "        dfstats.loc[rowstats,'dummyfp']=0\n",
    "    else:\n",
    "        dfstats.loc[rowstats,'far_price']=row.far_price\n",
    "        dfstats.loc[rowstats,'dummyfp']=1\n",
    "    return row\n",
    " \n",
    "  \n",
    "def interp(df,dfstats):\n",
    "    #dataframe operated on\n",
    "    #dfstats - dataframe with stats for each stock\n",
    "    #max seconds in bucket is 540, once you hit this then recalculate all 54 values\n",
    "    #for the next day\n",
    "    if(df.iloc[0,'seconds_in_bucket']==540):\n",
    "        #for each stock\n",
    "        for stock in dfstats.stock_id.unique():\n",
    "            #interpolate near price\n",
    "            index=dfstats[((dfstats.stock_id==stock)&(dfstats.dummynp==1))].index\n",
    "            low=dfstats.iloc[index.min()].near_price\n",
    "            dfstats.iloc[index[0]]=low\n",
    "            df.interpolate(limit=1, limit_direction='backward')\n",
    "            dfstats[(dfstats.stock_id==stock)].dummynp=0\n",
    "\n",
    "            #interpolate far price\n",
    "            index=dfstats[((dfstats.stock_id==stock)&(dfstats.dummyfp==1))].index\n",
    "            low=dfstats.iloc[index.min()].near_price\n",
    "            dfstats.iloc[index[0]]=low\n",
    "            df.interpolate(limit=1, limit_direction='backward')\n",
    "            dfstats[(dfstats.stock_id==stock)].dummyfp=0\n",
    "\n",
    "\n",
    "def estimate(df,dfstats):\n",
    "    #df - dataframe that needs near_price and far price interpolated\n",
    "    #dfstats- dataframe with stats for each stock\n",
    "\n",
    "    df.apply(fillrow, axis=1, args=(dfstats,))\n",
    "    interp(df,dfstats)\n",
    "    return df,dfstats\n",
    "\n",
    "\n",
    "dfstats=getdfstats()\n",
    "\n",
    "#get the last day of data for all stocks(200stocks*55 seconds_in_bucket per stock)\n",
    "cache=alldata[-11000:]\n",
    "\n",
    "#use the cache to populate dfstats\n",
    "_,dfstats=estimate(cache,dfstats)\n",
    "\n",
    "#get some test data\n",
    "df=getdfstats(numb_secs_day=1)\n",
    "\n",
    "#see if we can interpolate\n",
    "estimate(df,dfstats)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Stock:\n",
    "    #whenever a stock has a non null value add it to this dict \n",
    "    #in the form vals[seconds_in_bucket]=price\n",
    "    near_price_vals=defaultdict(lambda: 0)\n",
    "    far_price_vals=defaultdict(lambda: 0)\n",
    "\n",
    "class AllStocks: \n",
    "    def __init__(self):\n",
    "        self.allstocks=defaultdict(lambda: Stock)\n",
    "    def __getitem__(self,stock_id):\n",
    "        return self.allstocks[stock_id]\n",
    "    \n",
    "seconds_in_bucket=10\n",
    "stock_id=0\n",
    "a=AllStocks()\n",
    "seconds_in_bucket=10\n",
    "\n",
    "v1=a[stock_id].near_price_vals[seconds_in_bucket]\n",
    "a[stock_id].near_price_vals[seconds_in_bucket]=100\n",
    "v1=a[stock_id].near_price_vals[seconds_in_bucket]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the last row for all stocks (should be 200 rows if no stocks delisted)\n",
    "latest_date=df.date_id.max()\n",
    "latest_seconds_in_bucket=df[df.date_id==latest_date].seconds_in_bucket.max()\n",
    "dftmp=df[(df.date_id==latest_date) & (df.seconds_in_bucket==latest_seconds_in_bucket)]\n",
    "dftmp\n",
    "#save the values for near and far price for those stocks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "df = df.dropna(subset=[\"target\"])  #drop all rows with NaN in target\n",
    "df.sort_values(by=['stock_id','date_id','seconds_in_bucket'],inplace=True)\n",
    "df[109:141]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()\n",
    "# dfgb=df.groupby(['stock_id','date_id']).near_price.mean()\n",
    "\n",
    "#first do a forward interpolation\n",
    "df1.far_price=df1.far_price.interpolate(method='linear')\n",
    "df1.near_price=df1.near_price.interpolate(method='linear')\n",
    "# df1[109:141]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
